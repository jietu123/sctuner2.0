# 关于阶段四的问题简述

------

## 1. 当前问题的“精确定义”

你们现在的 Stage4（baseline vs plus_svg_type）在解冻 capacity 后，出现了三类核心现象：

### A) plus 改动幅度过大

- 在 capacity>1（mean≈3.42）的新设定下，plus 依然把解几乎“重算一遍”：
  **cell_assignment spot 改动 ≈ 99.94%**，type 改动 ≈ 76.9%。
  这和“tuner（只改难点处/保守微调）”的产品预期相冲突：它更像“换目标函数后重新求解”。

### B) plus 让 spot×type 更“混合”（不再尖锐）

- baseline：max(mean)=0.856，median(max)=1.0，one-hot≈63%
- plus：max(mean)=0.779，median(max)=0.8，one-hot≈48%
- 熵均值 baseline 0.264 → plus 0.406
  这说明 plus **没有在“更确定化”**，而是在“更混合化/更软化”。这未必错（Visium spot 本来可能混合），但需要评估体系证明“混合更接近真实”，否则就可能被解释为“更模糊”。

### C) marker sanity check：局部变好但不一致

- B/Mono/Fib 等谱系有明显更匹配的 marker 信号
- Endothelial / T CD8 等谱系证据偏弱
  这说明 plus **不是随机瞎改**，但也**没有呈现一致的全面改善**，更像“方向对、强度/权衡没校准好”。

------

## 2. 为什么这会被判为“问题”而不是“正常差异”

因为你们现在的目标不是“提出另一种完全不同的 mapping 方法”，而是**SVTuner：对 baseline 做可控增强**。因此在产品层面我们希望：

- plus 的改动主要集中在“baseline 不确定/弱证据”的位置
- 改动幅度可控（可调旋钮能把它压到合理区间）
- 在一组代理指标上（marker一致性/空间连续性/重构等）有可复现的增益
- 否则 Stage5/6 应该能自动选择 baseline（不强行宣称提升）

现在最大的问题就是：**改动幅度远超“可控增强”的直觉范围**，并且“更混合”这件事尚未被证明是好是坏。

------

## 3. 可能原因（按优先级）

> 你们已经定位到了一个根因：capacity=1 会触发置换敏感；现在解冻后仍然“全局翻盘”，说明还有“强度/机制”层面的原因。

### (1) 权重过强：lambda_prior / svg_refine_lambda 位于“主导优化”区间

- 当先验项/ refine 项强度过大时，最优解会整体跳到另一套结构，而不是在 baseline 附近微调。

### (2) 缺少“信任域/锚定机制”

你们当前的 plus 更像“从零开始用新目标求一个解”，而不是“在 baseline 解附近做小步更新”。
缺少以下任一类机制都会导致全局翻盘：

- 对 baseline 的显式约束/惩罚（trust-region penalty）
- 只对“模糊 spot/模糊 cell”启用增强（gating）
- 改动幅度上限（change budget）

### (3) harden/分配方式会放大全局跳变

即使 refine 是软的，只要最后 harden 是强制匹配/配额式的，全局会发生连锁反应，导致“看起来全改”。

### (4) capacity 来源虽解冻，但 clip_max=10/mean=3.42 仍可能对结构敏感

这不是 bug，只是意味着：你们的目标函数在新容量分布下仍然存在多个近似等价解，容易被先验拉走。

------

## 4. 后续修改的大致方案（符合你们节奏）

你问的是“为了后续修改准备”，所以我按**两阶段策略**写：

### 第一阶段：Stage5/6 先做“裁判与选择器”（建议先做）

目标：不用拍脑袋，先让系统告诉你“哪些参数区间是保守且不变差的”。

**Stage5（评估）最小闭环输出：**

1. 改动幅度：changed_spot_rate / changed_type_rate（相对 baseline）
2. marker 一致性：按大类+关键亚群（B/T/Mono/Fib/Endo/Epi）打分
3. 空间连续性：6-NN 同类比例、或邻域 JS/熵平滑度
4. （可选）重构/留出基因：等你们愿意再加

**Stage6（选择/仲裁）策略：**

- 设硬阈值：例如 changed_spot_rate > 0.8 直接判 “过强区间”
- 设软排序：marker↑、空间连续性不降（或下降不超过阈值）优先
- 如果 plus 全部不赢：自动选择 baseline（这是产品级正确行为）

**Stage5/6 的第一批 sweep（很小就够）：**

- lambda_prior ∈ {1.0, 0.3, 0.1, 0.0}
- svg_refine_lambda ∈ {0.5, 0.2, 0.0}
  （你们现在就能做，不需要改 Stage4 逻辑）

------

### 第二阶段：等 Stage5/6 找到“问题区间”后，再改 Stage4 的“校准机制”

如果 Stage5/6 发现“怎么扫都全局翻盘”，那就说明需要在 Stage4 引入**保守化机制**。我建议优先考虑下面两种（都是“可解释、可写进论文”的）：

#### 方案 A：Baseline 锚定（trust-region / mixing）

核心思想：plus 的目标不能离 baseline 太远。

做法（概念级）：

- 让 plus 的更新变成：
  `new = argmin( loss_data + lambda_prior*loss_prior + lambda_svg*loss_svg + gamma*distance_to_baseline )`
- distance_to_baseline 可以是：
  - cell→spot 分布的 KL/L2 距离
  - 或 spot×type fraction 与 baseline 的距离
- gamma 就是“保守强度旋钮”，gamma 越大越不可能全局翻盘。

优点：可控、稳定、很好解释（“tuning around baseline”）。

#### 方案 B：只对“模糊区域”启用增强（gating）

核心思想：plus 不是全局改，而是只改 baseline 没把握的部分。

做法（概念级）：

- 先从 baseline 计算不确定性（例如：type entropy、top1-top2 margin、邻域冲突）
- 定义 fuzzy spot/cell 集合，只对这些 spot/cell：
  - 使用 type prior 或 svg refine
- 其他保持 baseline 不动

优点：非常符合“插件/调谐器”定位；也更容易拿到“改动集中在难点处”的证据。

------

## 5. 你们后续“修改完成”的验收标准（写给未来自己/写进证据链）

当你们开始改 Stage4 校准机制时，建议用下面的验收判据判断“修好没”：

1. **改动幅度可控**：存在一组参数能把 changed_spot_rate 压到合理范围（比如 <30% 或你们自定）
2. **增益可复现**：在 marker 一致性/空间连续性中至少两项不劣并有提升趋势
3. **选择器能兜底**：如果 plus 不赢，Stage6 自动选 baseline（不硬吹）
4. **meta 可解释**：记录 gamma / gating_threshold / 变更预算等关键参数与 audit

------

